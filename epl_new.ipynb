{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring how team attributes impact scores in the premier league\n",
    "# approach is merge the match and (winning) team data to evaluate which team features most impact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database.sqlite\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sqlite3 as sql\n",
    "import matplotlib.pyplot as plt\n",
    "import helpers as h\n",
    "\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id  country_id                    name\n",
      "0  1729        1729  England Premier League\n",
      "       id  country_id                      name\n",
      "0       1           1    Belgium Jupiler League\n",
      "1    1729        1729    England Premier League\n",
      "2    4769        4769            France Ligue 1\n",
      "3    7809        7809     Germany 1. Bundesliga\n",
      "4   10257       10257             Italy Serie A\n",
      "5   13274       13274    Netherlands Eredivisie\n",
      "6   15722       15722        Poland Ekstraklasa\n",
      "7   17642       17642  Portugal Liga ZON Sagres\n",
      "8   19694       19694   Scotland Premier League\n",
      "9   21518       21518           Spain LIGA BBVA\n",
      "10  24558       24558  Switzerland Super League\n"
     ]
    }
   ],
   "source": [
    "# create the connection to the database\n",
    "con = None\n",
    "con = sql.connect('../input/database.sqlite')\n",
    "# create the cursor\n",
    "cur= con.cursor()\n",
    "# select only the information for the EPL\n",
    "#   - changed from sqlite interface to use pd.read_sql\n",
    "query = \"select * from League where name like '%England%'\"\n",
    "#eplinfo = cur.execute(\"select * from League where name like '%England%'\").fetchall()\n",
    "eplinfo = pd.read_sql(query,con=con) \n",
    "#print(type(eplinfo))\n",
    "print(eplinfo)\n",
    "query = \"select * from League\"\n",
    "leagues = pd.read_sql(query,con=con) #cur.execute().fetchall()\n",
    "#print(type(leagues))\n",
    "print(leagues)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get match information \n",
    "filter on epl and get the actual team names\n",
    "also select date, season, date and time, home team goal, away team goals, home team wins?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seasons = [\"2010/2011\"]\n",
    "\n",
    "#seasons = ['2008/2009','2009/2010','2010/2011']\n",
    "#get_matches_for_season\n",
    "\n",
    "\n",
    "# Set up the query to join the match information with the home and away team IDS\n",
    "#query = \"Select match_api_id, m.home_team_api_id, m.away_team_api_id, \\\n",
    "#        m.stage, m.date, t1.team_long_name as home_team, \\\n",
    "#        t2.team_long_name as away_team, m.home_team_goal, m.away_team_goal \\\n",
    "#        from Match as m join Team as t1 join Team as t2 \\\n",
    "#        on t1.team_api_id = m.home_team_api_id and t2.team_api_id = m.away_team_api_id  \\\n",
    "#        where m.league_id = {} and m.season='{}'\".format(eplinfo.id[0],season)\n",
    "#print(query)\n",
    "# get matches\n",
    "#m.id, m.match_api_id, m.home_team_api_id, m.away_team_api_id, \\\n",
    "#        m.stage, m.date, m.home_team_goal, m.away_team_goal from Match as'\n",
    "#query = \"Select * from Match \\\n",
    "#        where league_id = {} and season='{}'\".format(eplinfo.id[0],season)\n",
    "#queryall = \"Select * from Match where league_id = {}\".format(eplinfo.id[0])\n",
    "matches = h.get_matches_for_seasons(seasons) #h.get_matches_for_season(season) #pd.read_sql(query,con=con)\n",
    "allcols = matches.columns.tolist()\n",
    "#for e in xrange(len(allcols)):\n",
    "#    print \"{} - {}\".format(e,allcols[e])\n",
    "\n",
    "#matches[matches.columns[77:85]].head(20)\n",
    "\n",
    "matches = matches[matches.columns[:11]]\n",
    "#pd.concat([matches[matches.columns[:11]],matches[matches.columns[77:85]]])\n",
    "# get teams\n",
    "query = \"SELECT * FROM Team\"\n",
    "teams = pd.read_sql(query,con=con)\n",
    "\n",
    "query = \"SELECT * FROM Team_Attributes\" #where date >= '2010-07-01 00:00:00' and date <='2011-06-0100:00:00'\"\n",
    "team_attributes = h.get_attributes_for_seasons(seasons) #  pd.read_sql(query,con=con)\n",
    "#print(team_attributes[(team_attributes[\"date\"] >= '2010-07-01 00:00:00') & (team_attributes[\"date\"] <= '2011-06-0100:00:00')])\n",
    "#print(team_attributes.shape)\n",
    "#team_attributes.head()\n",
    "#matts = h.get_all_seasons_data(matches, team_attributes)\n",
    "#print(matts.shape)\n",
    "#print\n",
    "#print(matches['season'].unique())\n",
    "#print matches\n",
    "\n",
    "matches = h.merge_matches_teams(matches, teams)\n",
    "matches = h.merge_matches_attributes(matches, team_attributes)\n",
    "\n",
    "#print(matches.head().T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380, 53)\n"
     ]
    }
   ],
   "source": [
    "print(matches.shape)\n",
    "## pulled from Pete Hodges's kernel 'https://www.kaggle.com/petehodge/d/hugomathien/soccer/epl-weekly-predicting\n",
    "#matches = pd.merge(left=matches, right=teams, how='left', left_on='home_team_api_id', right_on='team_api_id')\n",
    "#matches = matches.drop(['country_id','league_id','id_y','team_api_id','team_fifa_api_id','team_short_name'], axis=1)\n",
    "#print(matches.shape)\n",
    "\n",
    "#matches.rename(columns={'id_x':'match_id','date':'match_date','team_long_name':'home_team'}, inplace=True)\n",
    "#matches = pd.merge(left=matches, right=teams, how='left', left_on='away_team_api_id', right_on='team_api_id')\n",
    "#matches = matches.drop(['id', 'match_api_id', 'team_fifa_api_id', 'team_short_name'], axis=1)\n",
    "\n",
    "#matches.rename(columns={'team_long_name':'away_team'}, inplace=True)\n",
    "#matches.head()\n",
    "#print(matches.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # do the same for the team attributes for the home and away teams\n",
    "# #matches = pd.merge(left=matches, right=team_attributes, how='left', left_on='home_team_api_id', right_on='team_api_id')\n",
    "# #matches = matches.drop(['id', 'team_fifa_api_id', 'team_api_id_x','team_api_id_y','date'], axis=1)\n",
    "# #matches.rename(columns={'buildUpPlaySpeed':'home_buildUpPlaySpeed','buildUpPlaySpeedClass':'home_buildUpPlaySpeedClass',\n",
    "#                         'buildUpPlayDribbling':'home_buildUpPlayDribbling',\n",
    "#                         'buildUpPlayDribblingClass':'home_buildUpPlayDribblingClass',\n",
    "#                         'buildUpPlayPassing':'home_buildUpPlayPassing','buildUpPlayPassingClass':'home_buildUpPlayPassingClass',\n",
    "#                         'buildUpPlayPositioningClass':'home_buildUpPlayPositioningClass',\n",
    "#                         'chanceCreationPassing':'home_chanceCreationPassing','chanceCreationPassingClass':'home_chanceCreationPassingClass',\n",
    "#                         'chanceCreationCrossing':'home_chanceCreationCrossing',\n",
    "#                         'chanceCreationCrossingClass':'home_chanceCreationCrossingClass','chanceCreationShooting':'home_chanceCreationShooting',\n",
    "#                         'chanceCreationShootingClass':'home_chanceCreationShootingClass','chanceCreationPositioningClass':'home_chanceCreationPositioningClass','defencePressure':'home_defencePressure',\n",
    "#                         'defencePressureClass':'home_defencePressureClass','defenceAggression':'home_defenceAggression',\n",
    "#                         'defenceAggressionClass':'home_defenceAggressionClass','defenceTeamWidth':'home_defenceTeamWidth',\n",
    "#                         'defenceTeamWidthClass':'home_defenceTeamWidthClass','defenceDefenderLineClass':'home_defenceDefenderLineClass'}, inplace=True)\n",
    "\n",
    "# matches = pd.merge(left=matches, right=team_attributes, how='left', left_on='away_team_api_id', right_on='team_api_id')\n",
    "# matches = matches.drop(['id', 'team_fifa_api_id', 'team_api_id', 'date'], axis=1)\n",
    "\n",
    "# matches.rename(columns={'buildUpPlaySpeed':'away_buildUpPlaySpeed','buildUpPlaySpeedClass':'away_buildUpPlaySpeedClass',\n",
    "#                         'buildUpPlayDribbling':'away_buildUpPlayDribbling',\n",
    "#                         'buildUpPlayDribblingClass':'away_buildUpPlayDribblingClass',\n",
    "#                         'buildUpPlayPassing':'away_buildUpPlayPassing','buildUpPlayPassingClass':'away_buildUpPlayPassingClass',\n",
    "#                         'buildUpPlayPositioningClass':'away_buildUpPlayPositioningClass',\n",
    "#                         'chanceCreationPassing':'away_chanceCreationPassing','chanceCreationPassingClass':'away_chanceCreationPassingClass',\n",
    "#                         'chanceCreationCrossing':'away_chanceCreationCrossing',\n",
    "#                         'chanceCreationCrossingClass':'away_chanceCreationCrossingClass','chanceCreationShooting':'away_chanceCreationShooting',\n",
    "#                         'chanceCreationShootingClass':'away_chanceCreationShootingClass','chanceCreationPositioningClass':'away_chanceCreationPositioningClass','defencePressure':'away_defencePressure',\n",
    "#                         'defencePressureClass':'away_defencePressureClass','defenceAggression':'away_defenceAggression',\n",
    "#                         'defenceAggressionClass':'away_defenceAggressionClass','defenceTeamWidth':'away_defenceTeamWidth',\n",
    "#                         'defenceTeamWidthClass':'away_defenceTeamWidthClass','defenceDefenderLineClass':'away_defenceDefenderLineClass'}, inplace=True)\n",
    "# print(matches.columns)\n",
    "\n",
    "\n",
    "# matches[\"home_team_points\"] = 3*(matches[\"home_team_goal\"] > matches[\"away_team_goal\"]) + 1*(matches[\"home_team_goal\"] == matches[\"away_team_goal\"])\n",
    "# #matches[\"home_team_points\"] = 1*(matches[\"home_team_goal\"] == matches[\"away_team_goal\"])\n",
    "# #print(matches.shape)\n",
    "# matches.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the match_id to be the dataset key.\n",
    "\n",
    "It is redundant to keep the home and away teams goals in the analysis since the output (whether the home team wins, loses or draws) is directly dependent on both features. So we'll remove them from the data set or not add them into our feature set. Other fields to exclude from the feature set include the match date (for now), the names of the teams playing etc.\n",
    "\n",
    "home_buildUpPlayDribbling and away_buildUpPlayDribbling have None entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#matches.index = matches['match_id']\n",
    "# then drop the match_id and also drop stage for now\n",
    "#to_drop = ['match_id', 'stage',  'match_date','home_team_api_id',\n",
    "#           'away_team_api_id','home_team', 'away_team','season',\n",
    "#           'home_buildUpPlayDribbling','away_buildUpPlayDribbling']  #'home_team_goal', 'away_team_goal',\n",
    "# make a copy of the matches dataframe and drop the appropriate fields while deleting the unneeded features\n",
    "#matches_ml = matches.drop(to_drop, axis =1)\n",
    "#print(matches_ml.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the data by converting categorical data to their one-hot encoded forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a list of all columns with categorical data\n",
    "#cat_list= matches_ml.select_dtypes(include=['object']).columns.tolist()\n",
    "#print(cat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##print(matches_ml.columns)\n",
    "#from sklearn.preprocessing import OneHotEncoder \n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "## pulled in from http://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn\n",
    "#class MultiColumnLabelEncoder:\n",
    "#    def __init__(self,columns = None):\n",
    "#        self.columns = columns # array of column names to encode\n",
    "\n",
    "#    def fit(self,X,y=None):\n",
    "#        return self # not relevant here\n",
    "\n",
    "#    def transform(self,X):\n",
    "#        '''\n",
    "#        Transforms columns of X specified in self.columns using\n",
    "#        LabelEncoder(). If no columns specified, transforms all\n",
    "#        columns in X.\n",
    "#       '''\n",
    "#        output = X.copy()\n",
    "#        if self.columns is not None:\n",
    "#            for col in self.columns:\n",
    "#                #print(col)\n",
    "#                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "#        else:\n",
    "#            for colname,col in output.iteritems():\n",
    "#                output[colname] = LabelEncoder().fit_transform(col)\n",
    "#        return output\n",
    "\n",
    "#    def fit_transform(self,X,y=None):\n",
    "#        return self.fit(X,y).transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#MultiColumnLabelEncoder(columns = cat_list ).fit_transform(matches_ml)\n",
    "#- Then convert those fields to encoded numeric forms\n",
    "#http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html\n",
    "#matches_ml = pd.get_dummies(matches_ml, prefix=cat_list)\n",
    "#print(new_matches.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches_ml = h.clean_up_matches(matches)\n",
    "matches_ml = h.encode_matches(matches_ml)\n",
    "\n",
    "matches_ml.head()\n",
    "#for i in [cat_list]:\n",
    "#    print(matches_ml.iloc[[1]][i])\n",
    "#    #print(\"field: {}, value: {}\".format(i,v))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# move the home team points to the target field\n",
    "y = np.array(matches_ml['home_team_points'])\n",
    "matches_ml.drop(['home_team_points'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = np.array(scaler.fit_transform(matches_ml))   #np.array(matches_ml) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Feature space holds %d observations and %d features\" % X.shape)\n",
    "print(\"Unique target space:\", y.shape)\n",
    "print(\"Unique target labels:\", np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for c in matches_ml.columns:\n",
    "#    print(matches_ml[c].isnull().values.any())\n",
    "#matches_ml.isnull().any()\n",
    "#matches_ml['home_team_points'].isnull().any()\n",
    "np.sum(np.isinf(X)*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "predictors = []\n",
    "clfs = ['LR','GBC','SVC','RF','KNN']\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline \n",
    "\n",
    "def plot_matrix(y_pred, y, clfname, ax):\n",
    "    #print(confusion_matrix(y, y_pred))\n",
    "    #print y_pred\n",
    "    #print y\n",
    "    print np.sum(y!=y_pred)/(1. * len(y))\n",
    "    #plt.figu\n",
    "    ax.imshow(confusion_matrix(y_pred, y),\n",
    "           cmap='Blues', interpolation='nearest')\n",
    "    #ax.ylabel('{} true'.format(clfname))\n",
    "    #ax.xlabel('{} predicted'.format(clfname))\n",
    "\n",
    "def run_cv(X,y,clf_class,**kwargs):\n",
    "    # Construct a kfolds object\n",
    "    kf = KFold(len(y),n_folds=3,shuffle=True)\n",
    "    y_pred = y.copy()\n",
    "    # Iterate through folds\n",
    "    for train_index, test_index in kf:\n",
    "        #print(\"train ={} test = {}\".format(train_index, test_index))\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        # Initialize a classifier with key word arguments\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred[test_index] = clf.predict(X_test)\n",
    "        predictors.append(clf)\n",
    "        #plot_matrix(clf.predict(X),y, '')\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def accuracy(y_true,y_pred):\n",
    "    # NumPy interpretes True and False as 1. and 0.\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "\n",
    "print(\"Logistiic Regression:\")\n",
    "print(\"%.3f\" % accuracy(y, run_cv(X,y,LR)))\n",
    "print(\"Gradient Boosting Classifier\")\n",
    "print(\"%.3f\" % accuracy(y, run_cv(X,y,GBC)))\n",
    "print(\"Support vector machines:\")\n",
    "print(\"%.3f\" % accuracy(y, run_cv(X,y,SVC)))\n",
    "print(\"Random forest:\")\n",
    "print(\"%.3f\" % accuracy(y, run_cv(X,y,RF)))\n",
    "print(\"K-nearest-neighbors:\")\n",
    "print(\"%.3f\" % accuracy(y, run_cv(X,y,KNN)))\n",
    "\n",
    "fig, ax = plt.subplots(2,3, sharex='col', sharey='row')\n",
    "#for i in xrange(len(clfs)):\n",
    "#    plot_matrix(predictors[i].predict(X),y, clfs[i],ax[i,np.mod(i,3)])\n",
    "#plt.colorbar()\n",
    "#plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "DO a simple classification exercise and see how many classes are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "max_clust = 0\n",
    "max_score = 0\n",
    "for i in range(20) :\n",
    "    n_clusters = i+2\n",
    "    clusterer = GaussianMixture(n_components=n_clusters, random_state= 11 )\n",
    "    clusterer = clusterer.fit(X)\n",
    "    # TODO: Predict the cluster for each data point\n",
    "    preds = clusterer.predict(X)\n",
    "    # TODO: Find the cluster centers\n",
    "    centers = clusterer.means_\n",
    "    # TODO: Predict the cluster for each transformed sample data point\n",
    "    #sample_preds = clusterer.predict(pca_samples)\n",
    "\n",
    "    # TODO: Calculate the mean silhouette coefficient for the number of clusters chosen\n",
    "    from sklearn.metrics import silhouette_score\n",
    "    score = silhouette_score(X,preds, random_state=10)\n",
    "\n",
    "    print \"For {} clusters , score is {}\".format(n_clusters, score)\n",
    "    if max_score < score:\n",
    "        max_score = score\n",
    "        max_clust = n_clusters\n",
    "    \n",
    "print \"Maximum cluster size and score: *{}* and *{}* \".format(max_clust, max_score)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"For DBScan\")\n",
    "db = DBSCAN(eps=0.1, min_samples=10).fit(X)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "print n_clusters\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(y, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(y, labels))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(y, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\"\n",
    "      % metrics.adjusted_rand_score(y, labels))\n",
    "print(\"Adjusted Mutual Information: %0.3f\"\n",
    "      % metrics.adjusted_mutual_info_score(y, labels))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
